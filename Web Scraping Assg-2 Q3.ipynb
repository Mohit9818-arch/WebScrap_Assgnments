{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78eaa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (4.7.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d40957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01f2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the driver-\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a43137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver-\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e86f241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukari page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71c6247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question-\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5639a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Absolute Path- In this link there is Single slash.\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afbcb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60f8abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkbox=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]\")\n",
    "checkbox.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b62a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cc88698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page, it is relative XPATH it is used to fetch more then one job\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "                                   \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdf18ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1da9ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - NLP (looking For early joiners)</td>\n",
       "      <td>Temp. WFH - Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist Iii</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist (Mlops) Iii</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weather and Climate Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analyst Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analyst Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Supply Chain</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist/Sr. Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Synechron</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Machine Learning Engineer II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Swiggy</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job_title  \\\n",
       "0  Data Scientist - NLP (looking For early joiners)   \n",
       "1                                Data Scientist Iii   \n",
       "2                        Data Scientist (Mlops) Iii   \n",
       "3                                    Data Scientist   \n",
       "4                Weather and Climate Data Scientist   \n",
       "5                              Analyst Data Science   \n",
       "6                              Analyst Data Science   \n",
       "7                     Data Scientist - Supply Chain   \n",
       "8                 Data Scientist/Sr. Data Scientist   \n",
       "9                      Machine Learning Engineer II   \n",
       "\n",
       "                                     Job_location      Company_name  \\\n",
       "0  Temp. WFH - Pune, Chennai, Bangalore/Bengaluru             Wipro   \n",
       "1                             Bangalore/Bengaluru           Walmart   \n",
       "2                             Bangalore/Bengaluru           Walmart   \n",
       "3                             Bangalore/Bengaluru           Infosys   \n",
       "4                             Bangalore/Bengaluru     Shell Pvt Ltd   \n",
       "5                                Gurgaon/Gurugram  AMERICAN EXPRESS   \n",
       "6                                Gurgaon/Gurugram  AMERICAN EXPRESS   \n",
       "7                             Bangalore/Bengaluru           Cargill   \n",
       "8                             Bangalore/Bengaluru         Synechron   \n",
       "9                             Bangalore/Bengaluru            Swiggy   \n",
       "\n",
       "  Exp_required  \n",
       "0      4-9 Yrs  \n",
       "1      4-7 Yrs  \n",
       "2      4-7 Yrs  \n",
       "3      3-5 Yrs  \n",
       "4     5-12 Yrs  \n",
       "5      0-3 Yrs  \n",
       "6      0-3 Yrs  \n",
       "7      3-5 Yrs  \n",
       "8     5-10 Yrs  \n",
       "9      3-4 Yrs  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c820a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

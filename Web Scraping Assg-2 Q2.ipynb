{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2b500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (4.7.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ce23fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60944b",
   "metadata": {},
   "source": [
    "Now we will download the WebDriver for the Web Browser.Steps for download are-1.Check the version of your browser. 2.go to the link\n",
    "https://chromedriver.chromium.org/downloads 3.Download the webdriver for your version of your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccc29f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver-\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\admin\\Downloads\\Compressed\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3076501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#les first connect to the driver-\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99967e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baaed08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question-\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8579765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Absolute Path- In this link there is Single slash.\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2049e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e8917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43bc70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page, it is relative XPATH it is used to fetch more then one job\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "                                   \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c94835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9825c118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Birlasoft</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Noida, Hyderabad...</td>\n",
       "      <td>Birlasoft</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - NLP (looking For early joiners)</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Iii</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist (Mlops) Iii</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...</td>\n",
       "      <td>Mindtree</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>10-12 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job_title  \\\n",
       "0                               Lead Data Scientist   \n",
       "1                  Analystics & Modeling Specialist   \n",
       "2                                    Data Scientist   \n",
       "3  Data Scientist - NLP (looking For early joiners)   \n",
       "4                                    Data Scientist   \n",
       "5                                Data Scientist Iii   \n",
       "6                        Data Scientist (Mlops) Iii   \n",
       "7                                    Data Scientist   \n",
       "8                             Senior Data Scientist   \n",
       "9                   Senior Principal Data Scientist   \n",
       "\n",
       "                                        Job_location  Company_name  \\\n",
       "0  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...     Birlasoft   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...     Accenture   \n",
       "2  Hybrid - Bangalore/Bengaluru, Noida, Hyderabad...     Birlasoft   \n",
       "3     Temp. WFH - Bangalore/Bengaluru, Pune, Chennai         Wipro   \n",
       "4                                Bangalore/Bengaluru       Walmart   \n",
       "5                                Bangalore/Bengaluru       Walmart   \n",
       "6                                Bangalore/Bengaluru       Walmart   \n",
       "7  Hybrid - Bangalore/Bengaluru, Noida, Kolkata, ...      Mindtree   \n",
       "8                        Bangalore/Bengaluru, Mumbai  Baker Hughes   \n",
       "9                                Bangalore/Bengaluru         Optum   \n",
       "\n",
       "  Exp_required  \n",
       "0     8-12 Yrs  \n",
       "1      6-8 Yrs  \n",
       "2     8-12 Yrs  \n",
       "3      4-9 Yrs  \n",
       "4      3-6 Yrs  \n",
       "5      4-7 Yrs  \n",
       "6      4-7 Yrs  \n",
       "7     5-10 Yrs  \n",
       "8      6-8 Yrs  \n",
       "9    10-12 Yrs  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from above data-\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Exp_required':experience_required})\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403dc2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
